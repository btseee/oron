train:
  log_interval: 100
  eval_interval: 1000
  seed: 1234
  epochs: 10000
  learning_rate: 2.0e-4
  betas: [0.8, 0.99]
  eps: 1.0e-9
  batch_size: 32
  fp16_run: true
  lr_decay: 0.999875
  segment_size: 8192
  init_lr_ratio: 1
  warmup_epochs: 0
  c_mel: 45
  c_kl_text: 0
  c_kl_dur: 2
  c_kl_audio: 0.05

data:
  training_files: data/prepared/filelists/train.txt
  validation_files: data/prepared/filelists/val.txt
  vocab_file: data/prepared/vocab.txt
  text_cleaners:
    - tokenize_text
    - add_bos_eos
  cleaned_text: false
  language: mn
  bits_per_sample: 16
  sample_rate: 22050
  n_fft: 1024
  hop_length: 256
  win_length: 1024
  n_mels: 80
  f_min: 0
  f_max: 8000
  n_speakers: 2
  use_mel: true

model:
  inter_channels: 192
  hidden_channels: 192
  filter_channels: 768
  n_heads: 2
  n_layers: 6
  n_layers_q: 12
  n_flows: 8
  kernel_size: 3
  p_dropout: 0.1
  speaker_cond_layer: 3
  resblock: "1"
  resblock_kernel_sizes: [3, 7, 11]
  resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
  upsample_rates: [8, 8, 2, 2]
  upsample_initial_channel: 512
  upsample_kernel_sizes: [16, 16, 4, 4]
  mas_noise_scale: 0.01
  mas_noise_scale_decay: 2.0e-6
  use_spectral_norm: false
  use_transformer_flow: true
  gin_channels: 256
